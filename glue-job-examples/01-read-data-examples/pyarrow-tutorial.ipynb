{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3f9a8c",
   "metadata": {},
   "source": [
    "# PyArrow Tutorial\n",
    "\n",
    "[CN]\n",
    "\n",
    "在大数据领域, 列式存储格式是用来存储大量数据并提供高性能查询的行业标准. 其中有两种数据格式非常流行 [Apache ORC](https://orc.apache.org/) [Apache Parquet](https://parquet.apache.org/). 其中 Parquet 要更流行一些. [Apache Arrow](https://arrow.apache.org/docs/index.html) 则是一个 in-memory analytics 的数据分析平台, 能把对这些流行的数据格式的 IO, transform 等操作整合起来的一个项目.\n",
    "\n",
    "在 Python 社区主流的用于数据分析的库是 [Pandas](https://pandas.pydata.org/). **PyArrow** 则是用 Python 操作 Apache Arrow 的一套 API, 同时可以用这套 API 操作 Parquet / ORC 数据格式. 并且提供了一套和 pandas 交互的接口.\n",
    "\n",
    "在小数据领域 pandas 基本已经够用了, 而在大数据领域, 学习 pyarrow 则是非常有必要的.\n",
    "\n",
    "---\n",
    "\n",
    "[EN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00c5965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (11.2.0)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from rich) (4.0.1)\n",
      "Requirement already satisfied: dataclasses<0.9,>=0.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from rich) (0.8)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from rich) (2.8.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from rich) (0.9.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from rich) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: smart_open in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: s3pathlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.5)\n",
      "Requirement already satisfied: pathlib-mate>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from s3pathlib) (1.0.2)\n",
      "Requirement already satisfied: autopep8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathlib-mate>=1.0.1->s3pathlib) (1.5.5)\n",
      "Requirement already satisfied: atomicwrites in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathlib-mate>=1.0.1->s3pathlib) (1.4.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathlib-mate>=1.0.1->s3pathlib) (1.15.0)\n",
      "Requirement already satisfied: pycodestyle>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autopep8->pathlib-mate>=1.0.1->s3pathlib) (2.6.0)\n",
      "Requirement already satisfied: toml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autopep8->pathlib-mate>=1.0.1->s3pathlib) (0.10.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pathlib_mate in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathlib_mate) (1.15.0)\n",
      "Requirement already satisfied: atomicwrites in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathlib_mate) (1.4.0)\n",
      "Requirement already satisfied: autopep8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathlib_mate) (1.5.5)\n",
      "Requirement already satisfied: pycodestyle>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autopep8->pathlib_mate) (2.6.0)\n",
      "Requirement already satisfied: toml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autopep8->pathlib_mate) (0.10.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyarrow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyarrow) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rich\n",
    "%pip install smart_open\n",
    "%pip install s3pathlib\n",
    "%pip install pathlib_mate\n",
    "%pip install pandas\n",
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "56ede6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from rich import print as rprint\n",
    "from s3pathlib import S3Path\n",
    "from pathlib_mate import Path\n",
    "\n",
    "dir_here = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "545e2cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prwjekzy'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rnd_str(length=8):\n",
    "    \"\"\"\n",
    "    Generate random length string.\n",
    "    \"\"\"\n",
    "    return \"\".join([random.choice(string.ascii_lowercase) for _ in range(length)])\n",
    "\n",
    "rnd_str(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7d746a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>awxfmamm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wwozwymi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>jniehyby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name\n",
       "0   1  awxfmamm\n",
       "1   2  wwozwymi\n",
       "2   3  jniehyby"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个 Pandas DataFarme\n",
    "n_rows = 1000\n",
    "df = pd.DataFrame()\n",
    "df[\"id\"] = range(1, n_rows+1)\n",
    "df[\"name\"] = [rnd_str(8) for _ in range(n_rows)]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa7f2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 pandas.DataFrame 转化为 pyarrow.Table\n",
    "# Ref: https://arrow.apache.org/docs/python/pandas.html\n",
    "table = pa.Table.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4fc41de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- method 1 ---\n",
      "id: int64\n",
      "name: string\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 470\n",
      "--- method 2 ---\n",
      "id: int64\n",
      "name: string\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 470\n"
     ]
    }
   ],
   "source": [
    "# method1. use Table.schema\n",
    "print(\"--- method 1 ---\")\n",
    "print(table.schema)\n",
    "\n",
    "# method2. read schema from pandas DataFrame\n",
    "print(\"--- method 2 ---\")\n",
    "schema = pa.Schema.from_pandas(df)\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ecda5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 pyarrow.Table 写入磁盘\n",
    "# Ref: https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html\n",
    "pq.write_table(table, Path(dir_here, \"users.parquet\").abspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f3f216e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>awxfmamm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wwozwymi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>jniehyby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name\n",
       "0   1  awxfmamm\n",
       "1   2  wwozwymi\n",
       "2   3  jniehyby"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从 磁盘读取 pyarrow.Table 数据\n",
    "# Ref: https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\n",
    "table = pq.read_table(Path(dir_here, \"users.parquet\").abspath)\n",
    "df = table.to_pandas()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be8b59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 pyarrow.Table 写入磁盘, 不过用的是 file object API\n",
    "# Ref: https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html\n",
    "p = Path(dir_here, \"users.parquet\")\n",
    "with p.open(\"wb\") as f:\n",
    "    pq.write_table(table, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91cf80c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>awxfmamm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wwozwymi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>jniehyby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name\n",
       "0   1  awxfmamm\n",
       "1   2  wwozwymi\n",
       "2   3  jniehyby"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从 磁盘读取 pyarrow.Table 数据, 不过用的是 file object API\n",
    "# Ref: https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\n",
    "with p.open(\"rb\") as f:\n",
    "    table = pq.read_table(f)\n",
    "df = table.to_pandas()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e415941b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>event_type_3</td>\n",
       "      <td>2000-01-01 00:00:00.000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>event_type_1</td>\n",
       "      <td>2000-01-01 00:00:02.678</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>event_type_1</td>\n",
       "      <td>2000-01-01 00:00:05.356</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id    event_type                    time  value\n",
       "0         1  event_type_3 2000-01-01 00:00:00.000     86\n",
       "1         2  event_type_1 2000-01-01 00:00:02.678     18\n",
       "2         3  event_type_1 2000-01-01 00:00:05.356     63"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows = 1000000\n",
    "event_type_list = [\"event_type_1\", \"event_type_2\", \"event_type_3\"]\n",
    "df = pd.DataFrame()\n",
    "df[\"event_id\"] = range(1, n_rows+1)\n",
    "df[\"event_type\"] = np.random.choice(event_type_list, n_rows)\n",
    "df[\"time\"] = pd.date_range(\"2000-01-01 00:00:00\", \"2000-01-31 23:59:59\", periods=n_rows)\n",
    "df[\"time\"] = df[\"time\"].astype(\"datetime64[ms]\")\n",
    "df[\"value\"] = np.random.randint(1, 100, n_rows)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc1581e",
   "metadata": {},
   "source": [
    "## Dictionary Encoding 字典编码\n",
    "\n",
    "``字典编码`` 就是将所有可能的值的总数不多的列用数字编码. 比如不超过 256 个可能值就可以用一个 8 位整数对其编码, 原始值很可能是字符串, 这样能大大节约存储空间.\n",
    "\n",
    "``use_dictionary`` 参数能控制是否自动使用字典编码, 还是只对指定的列使用. ``pyarrow`` 默认使用 dict encode, 如果不使用, 最后的文件会大一些. 特别注意的是, 被 dict encode 后的列只能用于 等于 和 不等于 的比较, 而无法利用该列的最大最小信息进行 range query 的优化.\n",
    "\n",
    "Ref:\n",
    "\n",
    "- [pyarrow.parquet.write_table](https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f22d289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events1.parquet file size = 11.31 MB\n",
      "events2.parquet file size = 13.63 MB\n"
     ]
    }
   ],
   "source": [
    "p = Path(dir_here, \"events1.parquet\")\n",
    "with p.open(\"wb\") as f:\n",
    "    pq.write_table(\n",
    "        pa.Table.from_pandas(df), \n",
    "        f,\n",
    "        use_dictionary=True, # default is True \n",
    "    )\n",
    "print(f\"{p.basename} file size = {p.size_in_text}\")\n",
    "\n",
    "p = Path(dir_here, \"events2.parquet\")\n",
    "with p.open(\"wb\") as f:\n",
    "    pq.write_table(\n",
    "        pa.Table.from_pandas(df), \n",
    "        f,\n",
    "        use_dictionary=False,\n",
    "    )\n",
    "print(f\"{p.basename} file size = {p.size_in_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f41cc1",
   "metadata": {},
   "source": [
    "## Row Group 行组\n",
    "\n",
    "``row_group_size``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ae9bc",
   "metadata": {},
   "source": [
    "### Row Group 越多, 占用的磁盘就越多, 但是扫描起来也就越快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9fea25b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共有 1000000 行\n",
      "一共有 1000 个 row group, events1.parquet file size = 14.75 MB\n",
      "一共有 1 个 row group, events2.parquet file size = 11.31 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"一共有 {df.shape[0]} 行\")\n",
    "# row group 越多, 占用磁盘越多, 但是扫描起来越有可能跳过不必要的数据块. row group 的数量最终需要取比较平衡的值.\n",
    "p = Path(dir_here, \"events1.parquet\")\n",
    "row_group_size = 1000\n",
    "n_row_groups = int(df.shape[0] / row_group_size)\n",
    "with p.open(\"wb\") as f:\n",
    "    pq.write_table(\n",
    "        pa.Table.from_pandas(df), \n",
    "        f,\n",
    "        row_group_size=row_group_size,\n",
    "    )\n",
    "print(f\"一共有 {n_row_groups} 个 row group, {p.basename} file size = {p.size_in_text}\")\n",
    "\n",
    "p = Path(dir_here, \"events2.parquet\")\n",
    "row_group_size = 1000000\n",
    "n_row_groups = int(df.shape[0] / row_group_size)\n",
    "with p.open(\"wb\") as f:\n",
    "    pq.write_table(\n",
    "        pa.Table.from_pandas(df), \n",
    "        f,\n",
    "        row_group_size=row_group_size,\n",
    "    )\n",
    "print(f\"一共有 {n_row_groups} 个 row group, {p.basename} file size = {p.size_in_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c2fa7c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a8abc357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarrow._parquet.Statistics object at 0x7f842a4685e8>\n",
      "  has_min_max: True\n",
      "  min: 2000-01-01 00:00:00\n",
      "  max: 2000-01-01 00:44:35.723000\n",
      "  null_count: 0\n",
      "  distinct_count: 0\n",
      "  num_values: 1000\n",
      "  physical_type: INT64\n",
      "  logical_type: Timestamp(isAdjustedToUTC=false, timeUnit=microseconds, is_from_converted_type=false, force_set_converted_type=false)\n",
      "  converted_type (legacy): NONE\n",
      "pyarrow.Table\n",
      "event_id: int64\n",
      "event_type: string\n",
      "time: timestamp[us]\n",
      "value: int64\n",
      "----\n",
      "event_id: [[1,2,3,4,5,6,7,8,9,10,...,991,992,993,994,995,996,997,998,999,1000]]\n",
      "event_type: [[\"event_type_3\",\"event_type_1\",\"event_type_1\",\"event_type_2\",\"event_type_1\",\"event_type_2\",\"event_type_1\",\"event_type_2\",\"event_type_2\",\"event_type_2\",...,\"event_type_3\",\"event_type_3\",\"event_type_1\",\"event_type_2\",\"event_type_3\",\"event_type_2\",\"event_type_2\",\"event_type_3\",\"event_type_1\",\"event_type_3\"]]\n",
      "time: [[2000-01-01 00:00:00.000000,2000-01-01 00:00:02.678000,2000-01-01 00:00:05.356000,2000-01-01 00:00:08.035000,2000-01-01 00:00:10.713000,2000-01-01 00:00:13.392000,2000-01-01 00:00:16.070000,2000-01-01 00:00:18.748000,2000-01-01 00:00:21.427000,2000-01-01 00:00:24.105000,...,2000-01-01 00:44:11.617000,2000-01-01 00:44:14.296000,2000-01-01 00:44:16.974000,2000-01-01 00:44:19.652000,2000-01-01 00:44:22.331000,2000-01-01 00:44:25.009000,2000-01-01 00:44:27.688000,2000-01-01 00:44:30.366000,2000-01-01 00:44:33.044000,2000-01-01 00:44:35.723000]]\n",
      "value: [[86,18,63,14,86,22,39,53,79,97,...,64,11,6,29,19,4,5,75,68,35]]\n"
     ]
    }
   ],
   "source": [
    "p = Path(dir_here, \"events.parquet\")\n",
    "with p.open(\"wb\") as f:\n",
    "    pq.write_table(\n",
    "        pa.Table.from_pandas(df), \n",
    "        f,\n",
    "        row_group_size=1000,\n",
    "    )\n",
    "\n",
    "# columns: [\"event_id\", \"event_type\", \"time\", \"value\"]\n",
    "pq_file = pq.ParquetFile(p.abspath)\n",
    "for ith_row_group in range(pq_file.metadata.num_row_groups):\n",
    "    rg_meta = pq_file.metadata.row_group(ith_row_group)\n",
    "    print(rg_meta.column(2).statistics)\n",
    "    rg = pq_file.read_row_group(ith_row_group)\n",
    "    print(rg)\n",
    "    print(rg_meta.column(0))\n",
    "    print(rg_meta.column(0).statistics.min)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead99b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
